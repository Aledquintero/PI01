{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importación de librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importacion de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Datos\\data.csv\")\n",
    "#Los datos cambian de tipo con la exportacion a CSV por lo que tenemos que corregirlo\n",
    "data.listed_in = data.listed_in.apply(eval)\n",
    "data.cast = data.cast.apply(eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocesamiento de features**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No utilizaremos todas las columnas en nuestro modelo por lo que seleccionamos las que creemos necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionamos las columnas que nos interesan\n",
    "data_f = data[['type', \"title\", 'cast', 'show_id', 'antiquity_category', 'duration_category', 'listed_in', 'Promedio_Valoraciones']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para combatir un poco los outliers filtramos los datos, ignoramos todos los actores que hayan participado en menos de 5 peliculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = data_f['cast'].apply(pd.Series).stack().value_counts()\n",
    "\n",
    "# Seleccionar aquellos actores cuya frecuencia es mayor que 5\n",
    "filtro = freq[freq > 5].index\n",
    "\n",
    "# Filtrar el DataFrame para mantener solo las filas que contienen actores que hayan participado en mas de 5 peliculas\n",
    "data = data_f[data_f['cast'].apply(lambda x: any(item in filtro for item in x))]\n",
    "\n",
    "# Reordenar los indices\n",
    "data = data.reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONE-HOT-ENCODING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiLabelBinarizer codifica en un array binario las columnas que contienen listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia del codificador one-hot\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(data['listed_in'])\n",
    "actors_encoded = mlb.fit_transform(data['cast'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder codifica en un array binario las columnas que contienen listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_encoder = OneHotEncoder(sparse=False)\n",
    "antiquity_encoded = oh_encoder.fit_transform(data[['antiquity_category']])\n",
    "duration_encoded = oh_encoder.fit_transform(data[['duration_category']])\n",
    "id_encoded = oh_encoder.fit_transform(data[['show_id']])\n",
    "\n",
    "duration_encoded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos todos nuestros arrays binarios en uno solo para poder entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenamos todos los array\n",
    "data_m = np.concatenate((actors_encoded, genres_encoded, antiquity_encoded, duration_encoded,id_encoded), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modelo K-vecinos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sabemos, el modelo k-vecinos predice sus datos en base a similtudes entre el input y el conjunto de datos que es justamente lo que buscamos en un sistema de recomendación de peliculas, es por ello que lo escogemos como nuestro modelo ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='cosine')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un modelo de k-vecinos con 5 vecinos\n",
    "model = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "\n",
    "# Entrenar el modelo con los datos codificados\n",
    "model.fit(data_m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a ejecutar una recomendacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.51 GiB for an array with shape (13465, 44999) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13756/3454334976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmovie_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'show_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"as7611\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_m\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmovie_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[0;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1621\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1623\u001b[1;33m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0m\u001b[0;32m   1624\u001b[0m                                      n_jobs=n_jobs, **kwds)\n\u001b[0;32m   1625\u001b[0m         if ((X is Y or Y is None)\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_distances\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m    831\u001b[0m     \"\"\"\n\u001b[0;32m    832\u001b[0m     \u001b[1;31m# 1.0 - cosine_similarity(X, Y) without copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m     \u001b[0mS\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m     \u001b[0mS\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1902\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'%d' is not a supported axis\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1904\u001b[1;33m     X = check_array(X, accept_sparse=sparse_format, copy=copy,\n\u001b[0m\u001b[0;32m   1905\u001b[0m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0;32m   1906\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ale\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.51 GiB for an array with shape (13465, 44999) and data type float64"
     ]
    }
   ],
   "source": [
    "movie_index = data.loc[data['show_id'].apply(lambda x: \"as7611\" in x)].index\n",
    "distances, indices = model.kneighbors(data_m[movie_index].reshape(1,-1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un pequeño output para ver que tal funciona nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13756/124580575.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mindex_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_p\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'indices' is not defined"
     ]
    }
   ],
   "source": [
    "index_p = list(indices[0])\n",
    "\n",
    "data.iloc[index_p]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AT LEAST SQUARE**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una app spark para poder manipular grandes volumenes de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"my_app\") \\\n",
    "        .config(\"spark.driver.memory\", \"10g\") \\\n",
    "        .config(\"spark.executor.memory\", \"10g\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.pivotMaxValues\", 30000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos todos los CSV con spark, no pudimos exportarlos en un csv con anterioridad por un error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos estas tablas con spark por su tamaño\n",
    "d1 = spark.read.csv(\"MLOpsReviews/ratings/1.csv\", header=True, inferSchema=True)\n",
    "d2 = spark.read.csv(\"MLOpsReviews/ratings/2.csv\", header=True, inferSchema=True)\n",
    "d3 = spark.read.csv(\"MLOpsReviews/ratings/3.csv\", header=True, inferSchema=True)\n",
    "d4 = spark.read.csv(\"MLOpsReviews/ratings/4.csv\", header=True, inferSchema=True)\n",
    "d5 = spark.read.csv(\"MLOpsReviews/ratings/5.csv\", header=True, inferSchema=True)\n",
    "d6 = spark.read.csv(\"MLOpsReviews/ratings/6.csv\", header=True, inferSchema=True)\n",
    "d7 = spark.read.csv(\"MLOpsReviews/ratings/7.csv\", header=True, inferSchema=True)\n",
    "d8 = spark.read.csv(\"MLOpsReviews/ratings/8.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos todos los CSV en un solo dataframe de ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [d1, d2, d3, d4, d5, d6, d7, d8]\n",
    "\n",
    "ratings = df_list[0]\n",
    "for i in range(1, len(df_list)):\n",
    "   ratings = ratings.union(df_list[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una columna movie_index porque el modelo solo recibe parametros numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dense_rank, col\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "# Crea un mapeo de los IDs de película únicos a enteros\n",
    "movie_id_mapping = (ratings.select(\"movieId\")\n",
    "                   .distinct()\n",
    "                   .orderBy(\"movieId\")\n",
    "                   .select(dense_rank().over(Window.orderBy(\"movieId\")).alias(\"movie_index\"), col(\"movieId\"))\n",
    "                   .cache())\n",
    "\n",
    "# Crea una nueva columna \"movie_index\" en el dataframe \"ratings\" con los IDs de película mapeados a enteros\n",
    "ratings_with_index = ratings.join(movie_id_mapping, on=\"movieId\", how=\"inner\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un modelo ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = nan\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Crear el modelo ALS\n",
    "als = ALS(rank=10, maxIter=15, regParam=0.01, userCol=\"userId\", itemCol=\"movie_index\", ratingCol=\"rating\")\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "(training, test) = ratings_with_index.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model = als.fit(training)\n",
    "\n",
    "# Realizar predicciones en los datos de prueba\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Calcular el error RMSE en las predicciones\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# Obtener las recomendaciones para todos los usuarios\n",
    "user_recs = model.recommendForAllUsers(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pandas**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El numero de filas en user_recs ya no supera los 200.000 registros por lo que nos conviene transformar el dataframe a pandas el dataframe con las predicciones para todos los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_recs.toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos algunas recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>antiquity_category</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration_int</th>\n",
       "      <th>duration_type</th>\n",
       "      <th>duration_category</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "      <th>Valoraciones</th>\n",
       "      <th>Promedio_Valoraciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>as5819</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Ed Hill: Candy and Smiley</td>\n",
       "      <td>Jeremy Podlog</td>\n",
       "      <td>[Ed Hill]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021</td>\n",
       "      <td>Nueva</td>\n",
       "      <td>13+</td>\n",
       "      <td>68</td>\n",
       "      <td>min</td>\n",
       "      <td>Corta</td>\n",
       "      <td>[Arts, Entertainment, and Culture, Comedy]</td>\n",
       "      <td>Candy &amp; Smiley is relevant, realistic, and at ...</td>\n",
       "      <td>479</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>ns4429</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Christmas With A View</td>\n",
       "      <td>Justin G. Dyck</td>\n",
       "      <td>[Scott Cavalheiro, Kaitlyn Leeb, Vivica A. Fox...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2018-11-01 00:00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Vieja</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>91</td>\n",
       "      <td>min</td>\n",
       "      <td>Corta</td>\n",
       "      <td>[International Movies, Romantic Movies]</td>\n",
       "      <td>Still reeling from a business failure, the res...</td>\n",
       "      <td>497</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13693</th>\n",
       "      <td>as5980</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Ringolevio</td>\n",
       "      <td>Kristin Peterson Kaszubowski</td>\n",
       "      <td>[Joshua Koopman, Meredith Johnston, Cory Hardin]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "      <td>Nueva</td>\n",
       "      <td>18+</td>\n",
       "      <td>81</td>\n",
       "      <td>min</td>\n",
       "      <td>Corta</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>Ada, a reserved young woman with a passion for...</td>\n",
       "      <td>485</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19541</th>\n",
       "      <td>hs1819</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Basketball: A Love Story</td>\n",
       "      <td>None</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-02-05 00:00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Vieja</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>1</td>\n",
       "      <td>Season</td>\n",
       "      <td>Corta</td>\n",
       "      <td>[Documentaries, Sports]</td>\n",
       "      <td>A series of short stories that feature intervi...</td>\n",
       "      <td>428</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>hs2689</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>XxxHolic</td>\n",
       "      <td>None</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2017-09-05 00:00:00</td>\n",
       "      <td>2006</td>\n",
       "      <td>Vieja</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>1</td>\n",
       "      <td>Season</td>\n",
       "      <td>Corta</td>\n",
       "      <td>[Anime, Drama, Horror]</td>\n",
       "      <td>There is no such thing as coincidence, there i...</td>\n",
       "      <td>474</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      show_id     type                      title  \\\n",
       "1308   as5819    Movie  Ed Hill: Candy and Smiley   \n",
       "8509   ns4429    Movie      Christmas With A View   \n",
       "13693  as5980    Movie                 Ringolevio   \n",
       "19541  hs1819  TV Show   Basketball: A Love Story   \n",
       "19656  hs2689  TV Show                   XxxHolic   \n",
       "\n",
       "                           director  \\\n",
       "1308                  Jeremy Podlog   \n",
       "8509                 Justin G. Dyck   \n",
       "13693  Kristin Peterson Kaszubowski   \n",
       "19541                          None   \n",
       "19656                          None   \n",
       "\n",
       "                                                    cast country  \\\n",
       "1308                                           [Ed Hill]    None   \n",
       "8509   [Scott Cavalheiro, Kaitlyn Leeb, Vivica A. Fox...  Canada   \n",
       "13693   [Joshua Koopman, Meredith Johnston, Cory Hardin]    None   \n",
       "19541                                             [None]    None   \n",
       "19656                                             [None]   Japan   \n",
       "\n",
       "                date_added  release_year antiquity_category rating  \\\n",
       "1308                  None          2021              Nueva    13+   \n",
       "8509   2018-11-01 00:00:00          2018              Vieja  TV-PG   \n",
       "13693                 None          2020              Nueva    18+   \n",
       "19541  2020-02-05 00:00:00          2018              Vieja   TV-G   \n",
       "19656  2017-09-05 00:00:00          2006              Vieja  TV-PG   \n",
       "\n",
       "       duration_int duration_type duration_category  \\\n",
       "1308             68           min             Corta   \n",
       "8509             91           min             Corta   \n",
       "13693            81           min             Corta   \n",
       "19541             1        Season             Corta   \n",
       "19656             1        Season             Corta   \n",
       "\n",
       "                                        listed_in  \\\n",
       "1308   [Arts, Entertainment, and Culture, Comedy]   \n",
       "8509      [International Movies, Romantic Movies]   \n",
       "13693                    [Comedy, Drama, Romance]   \n",
       "19541                     [Documentaries, Sports]   \n",
       "19656                      [Anime, Drama, Horror]   \n",
       "\n",
       "                                             description  Valoraciones  \\\n",
       "1308   Candy & Smiley is relevant, realistic, and at ...           479   \n",
       "8509   Still reeling from a business failure, the res...           497   \n",
       "13693  Ada, a reserved young woman with a passion for...           485   \n",
       "19541  A series of short stories that feature intervi...           428   \n",
       "19656  There is no such thing as coincidence, there i...           474   \n",
       "\n",
       "       Promedio_Valoraciones  \n",
       "1308                     3.6  \n",
       "8509                     3.5  \n",
       "13693                    3.4  \n",
       "19541                    3.5  \n",
       "19656                    3.5  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 4\n",
    "\n",
    "lista_id = []\n",
    "for i in list(df.recommendations.loc[df.userId == user_id])[0]:\n",
    "    lista_id.append(ratings_with_index.select(\"movieId\").filter(col(\"movie_index\") == i[0]).first()[0])\n",
    "    \n",
    "data.loc[data.show_id.isin(lista_id)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8347626938f0c92124cdd47ea83c678aa811759c184b91c50a888eac869421fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
